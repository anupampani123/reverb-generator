{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Reverberator",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1R0fOlRP4_9zDjcFwFsCJJ_m0Eo8vgyEI",
      "authorship_tag": "ABX9TyOZC7zGQkpTYmnwsM+znjIl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupampani123/reverb-generator/blob/main/Reverberator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SrW6rIvBU0v"
      },
      "source": [
        "#Building a model to add the reverb effect \n",
        "# Variational autoencoder is used so that the relationship between classes during decoding isnt lost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n1LXjfNOXfA"
      },
      "source": [
        "import numpy as np\n",
        "import librosa as lr\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import soundfile as sf\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import librosa.display\n",
        "import librosa \n",
        "import random\n",
        "import tensorflow \n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxdnCKiYtDvk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD_YRO2kP64w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfhez-KDvYRa"
      },
      "source": [
        "def fix_specgram_shape(spec, shape=(512,128)):\n",
        "    \"\"\"Fix spectrogram shape to user specified size.\n",
        "    Args:\n",
        "        spec: 2D spectrogram [freqs, time].\n",
        "        shape: 2D output spectrogram shape [freqs, time].\n",
        "    Returns:\n",
        "        fixed_spec: fixed 2D output spectrogram [freqs, time].\n",
        "    \"\"\"\n",
        "    if spec.shape[1] < shape[1]: # pad the input to be of shape (513, 750)\n",
        "        out = np.zeros(shape)\n",
        "        out[:spec.shape[0],:spec.shape[1]] = spec\n",
        "    else: # crop the input to be of shape (513, 750)\n",
        "        out = spec[:,:shape[1]]\n",
        "\n",
        "    if spec.shape[0] < shape[0]: # pad the input to be of shape (513, 750)\n",
        "        out = np.zeros(shape)\n",
        "        out[:spec.shape[0],:spec.shape[1]] = spec\n",
        "    else: # crop the input to be of shape (513, 750)\n",
        "        out = spec[:shape[0],:]\n",
        "            \n",
        "    return out\n",
        "\n",
        "def generate_z(encoder, spec):\n",
        "    \"\"\"\n",
        "    Determine the latent representation of a spectrogram.\n",
        "    Args:\n",
        "        encoder (obj): trained Keras encoder network.\n",
        "        spec (ndarray): spectrogram of shape (freqs, time).\n",
        "    Returns:\n",
        "        z (ndarray): latent vector of shape (1, 1, 1, 3)\n",
        "    \"\"\"\n",
        "    # fix shape (may be longer or shorter)\n",
        "    spec_shape = (encoder.input_shape[1], encoder.input_shape[2])\n",
        "    spec = fix_specgram_shape(spec, spec_shape)\n",
        "\n",
        "    # reshape for input to the encoder\n",
        "    spec = np.reshape(spec, (1, spec.shape[0], spec.shape[1], 1))\n",
        "\n",
        "    # predict embedding to latent vector z\n",
        "    z = encoder.predict(spec)\n",
        "\n",
        "    return z\n",
        "\n",
        "def generate_specgram(decoder, z):\n",
        "    \"\"\"\n",
        "    Generate a spectrogram from a latent representation.\n",
        "    Args:\n",
        "        decoder (obj): trained Keras decoder network.\n",
        "        z (ndarray): latent vector of shape (1, 1, 1, 3).\n",
        "    Returns:\n",
        "        spec (ndarray): spectrogram of shape (freqs, time).\n",
        "    \"\"\"\n",
        "    spec = decoder.predict(z) # predict spectrogram\n",
        "    spec = np.reshape(spec, (spec.shape[1], spec.shape[2]))\n",
        "    return spec\n",
        "\n",
        "def audio_from_specgram(spec, rate, output):\n",
        "    \"\"\"\n",
        "    Reconstruct audio and save it to file.\n",
        "    Args:\n",
        "        spec (ndarray): spectrogram of shape (freqs, time).\n",
        "        rate (int): sample rate of input audio.\n",
        "        output (str): path to output file.\n",
        "    \"\"\"\n",
        "    spec = np.reshape(spec, (spec.shape[0], spec.shape[1], 1)) # reshape\n",
        "    audio = ispecgram(spec, n_fft=1024, hop_length=256, mag_only=True, num_iters=1000)\n",
        "    sf.write(output + '.wav', audio, rate) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgK6QGOCxqQB"
      },
      "source": [
        "def inv_magphase(mag, phase_angle):\n",
        "    phase = np.cos(phase_angle) + 1.j * np.sin(phase_angle)\n",
        "    return mag * phase\n",
        "\n",
        "def griffin_lim(mag, phase_angle, n_fft, hop, num_iters):\n",
        "    \"\"\"Iterative algorithm for phase retrival from a magnitude spectrogram.\n",
        "    Args:\n",
        "        mag: Magnitude spectrogram.\n",
        "        phase_angle: Initial condition for phase.\n",
        "        n_fft: Size of the FFT.\n",
        "        hop: Stride of FFT. Defaults to n_fft/2.\n",
        "        num_iters: Griffin-Lim iterations to perform.\n",
        "    Returns:\n",
        "        audio: 1-D array of float32 sound samples.\n",
        "    \"\"\"\n",
        "    fft_config = dict(n_fft=n_fft, win_length=n_fft, hop_length=hop, center=True)\n",
        "    ifft_config = dict(win_length=n_fft, hop_length=hop, center=True)\n",
        "    complex_specgram = inv_magphase(mag, phase_angle)\n",
        "    for i in range(num_iters):\n",
        "        audio = librosa.istft(complex_specgram, **ifft_config)\n",
        "        if i != num_iters - 1:\n",
        "            complex_specgram = librosa.stft(audio, **fft_config)\n",
        "            _, phase = librosa.magphase(complex_specgram)\n",
        "            phase_angle = np.angle(phase)\n",
        "            complex_specgram = inv_magphase(mag, phase_angle)\n",
        "    return audio\n",
        "\n",
        "def ispecgram(spec,\n",
        "              n_fft=512,\n",
        "              hop_length=None,\n",
        "              mask=True,\n",
        "              log_mag=True,\n",
        "              re_im=False,\n",
        "              dphase=True,\n",
        "              mag_only=True,\n",
        "              num_iters=1000):\n",
        "    \"\"\"Inverse Spectrogram using librosa.\n",
        "    Args:\n",
        "        spec: 3-D specgram array [freqs, time, (mag_db, dphase)].\n",
        "        n_fft: Size of the FFT.\n",
        "        hop_length: Stride of FFT. Defaults to n_fft/2.\n",
        "        mask: Reverse the mask of the phase derivative by the magnitude.\n",
        "        log_mag: Use the logamplitude.\n",
        "        re_im: Output Real and Imag. instead of logMag and dPhase.\n",
        "        dphase: Use derivative of phase instead of phase.\n",
        "        mag_only: Specgram contains no phase.\n",
        "        num_iters: Number of griffin-lim iterations for mag_only.\n",
        "    Returns:\n",
        "        audio: 1-D array of sound samples. Peak normalized to 1.\n",
        "    \"\"\"\n",
        "    if not hop_length:\n",
        "        hop_length = n_fft // 2\n",
        "\n",
        "    ifft_config = dict(win_length=n_fft, hop_length=hop_length, center=True)\n",
        "\n",
        "    if mag_only:\n",
        "        mag = spec[:, :, 0]\n",
        "        phase_angle = np.pi * np.random.rand(*mag.shape)\n",
        "    elif re_im:\n",
        "        spec_real = spec[:, :, 0] + 1.j * spec[:, :, 1]\n",
        "    else:\n",
        "        mag, p = spec[:, :, 0], spec[:, :, 1]\n",
        "        if mask and log_mag:\n",
        "            p /= (mag + 1e-13 * np.random.randn(*mag.shape))\n",
        "        if dphase:\n",
        "            # Roll up phase\n",
        "            phase_angle = np.cumsum(p * np.pi, axis=1)\n",
        "        else:\n",
        "            phase_angle = p * np.pi\n",
        "\n",
        "    # Magnitudes\n",
        "    if log_mag:\n",
        "        mag = (mag - 1.0) * 120.0\n",
        "        mag = 10**(mag / 20.0)\n",
        "    phase = np.cos(phase_angle) + 1.j * np.sin(phase_angle)\n",
        "    spec_real = mag * phase\n",
        "\n",
        "    if mag_only:\n",
        "        audio = griffin_lim(\n",
        "            mag, phase_angle, n_fft, hop_length, num_iters=num_iters)\n",
        "    else:\n",
        "        audio = librosa.core.istft(spec_real, **ifft_config)\n",
        "    return np.squeeze((audio / audio.max()) * 0.25) # scale to -12dB peak"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hKoc5e6M-G-"
      },
      "source": [
        "img_size1=513;\n",
        "img_size2=128;\n",
        "num_channels=1;\n",
        "latent_space_dim=3;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgsmJdA3Z-Tr"
      },
      "source": [
        "filelist = []\n",
        "path=\"/content/drive/MyDrive/Suga/spect_text\" #change to spect text\n",
        "for root, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "    name=os.path.join(root,file)\n",
        "    if \".txt\" not in name:\n",
        "      continue\n",
        "    else:\n",
        "      filelist.append(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP0vYXlivXnx"
      },
      "source": [
        "#Get the spectrogram data\n",
        "\n",
        "def load_specgrams(filelist, spec_shape, train_split=0.80, n_samples=None):\n",
        "    \"\"\"\n",
        "    Utility function to load spectogram data.\n",
        "    Args:\n",
        "        dataset_dir (str): Directory containing the dataset.\n",
        "        spec_shape (tuple) : Shape of spectrograms to be loaded (freqs, time)\n",
        "        train_split (float, optional): Fraction of the data to return as training samples.\n",
        "        n_samples (int, optional): Number of total dataset examples to load. \n",
        "            (Deafults to full size of the dataset)\n",
        "    Returns:\n",
        "        x_train (ndarray): Training set (samples, freqs, time).\n",
        "        x_test (ndarray): Testing set (samples, freqs, time).\n",
        "    \"\"\"\n",
        "    if n_samples is None: # set number of samples to full dataset\n",
        "        n_samples = len(filelist)\n",
        "\n",
        "    x = [] # list to hold spectrograms\n",
        "    for idx,sample in enumerate(filelist):\n",
        "        if idx < n_samples:\n",
        "            s = np.loadtxt(sample)\n",
        "            out = fix_specgram_shape(s, spec_shape)\n",
        "            x.append(out) # create list of spectrograms\n",
        "\n",
        "\n",
        "    x = np.stack(x, axis=0)\n",
        "\n",
        "    train_idx = np.floor(n_samples*train_split).astype('int')\n",
        "    x_train = x[:train_idx,:,:]\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0],spec_shape[0], x_train.shape[2], 1))\n",
        "    x_test = x[train_idx:,:,:]\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], spec_shape[0], x_test.shape[2], 1))\n",
        "\n",
        "    print(\"x_train: {}\".format(x_train.shape))\n",
        "    print(\"x_test:  {}\".format(x_test.shape))\n",
        "\n",
        "    return x_train, x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzQPBKXrN3P0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615fce30-8f83-4ed0-839a-3ccc916a7b69"
      },
      "source": [
        "# #get images from in numpy format \n",
        "\n",
        "# path =\"/content/drive/MyDrive/Suga/spectograms\"\n",
        "# #we shall store all the file names in this list\n",
        "# filelist = []\n",
        "# img_data_array=[]\n",
        "# i=0;\n",
        "\n",
        "# for root, dirs, files in os.walk(path):\n",
        "# \tfor file in files:\n",
        "#         #append the file name to the list\n",
        "# \t\tfilelist.append(os.path.join(root,file))\n",
        "\n",
        "# #print all the file names\n",
        "# for name in filelist:\n",
        "#     image= cv2.imread(name, cv2.COLOR_BGR2RGB)\n",
        "#     image=np.array(image)\n",
        "#     image = image.astype('float32')\n",
        "#     image /= 255 \n",
        "#     img_data_array.append(image)\n",
        "\n",
        "\n",
        "# print(\"done adding images\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done adding images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDDguMFCc-32"
      },
      "source": [
        "train_data,test_data=load_specgrams(filelist,(img_size1,img_size2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDC3I4Y0qUtt"
      },
      "source": [
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlWa1Qn8pd61"
      },
      "source": [
        "def build_spectral_ae(input_shape=(513, 128, 1), latent_dim=2, n_filters=[32, 64, 128, 256, 512], lr=0.01):\n",
        "\n",
        "    f1 = n_filters[0]\n",
        "    f2 = n_filters[1]\n",
        "    f3 = n_filters[2]\n",
        "    f4 = n_filters[3]\n",
        "\n",
        "    input_spect = layers.Input(input_shape)\n",
        "    x = layers.Conv2D(f1, (5,5), padding='same', strides=(2,2))(input_spect)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f1, (4,4), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f1, (4,4), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f2, (4,4), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f2, (4,4), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f2, (4,4), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f3, (4,4), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f3, (4,4), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f3, (4,4), padding='same', strides=(2,1))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(f4, (1,1), padding='same', strides=(2,1))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(latent_dim, (1,1), padding='same', strides=(1,1))(x)\n",
        "    z = layers.BatchNormalization()(x)\n",
        "\n",
        "    input_z = layers.Input(shape=(1, 1, latent_dim))\n",
        "    x = layers.Conv2DTranspose(f4, (1,1), padding='same', strides=(1,1))(input_z)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f3, (2,2), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f3, (2,2), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f3, (2,2), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f2, (2,2), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f2, (2,2), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f2, (2,2), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f1, (2,2), padding='same', strides=(2,2))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f1, (2,2), padding='same', strides=(2,1))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(f1, (3,1), padding='valid', strides=(2,1))(x)\n",
        "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    output_spect = layers.Conv2DTranspose(1, (1,1), padding='same', strides=(1,1))(x)\n",
        "    \n",
        "    encoder = Model(input_spect, z)\n",
        "    encoder.summary()\n",
        "\n",
        "    decoder = Model(input_z, output_spect)\n",
        "    decoder.summary()\n",
        "\n",
        "    outputs = decoder(encoder(input_spect))\n",
        "    autoencoder = Model(input_spect, outputs)\n",
        "    autoencoder.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=lr), loss='mean_squared_error')\n",
        "    autoencoder.summary()\n",
        "    \n",
        "    return encoder, decoder, autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md0_jWEfqbxG"
      },
      "source": [
        "from keras.models import Model\n",
        "e, d, ae = build_spectral_ae()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG9g2Go3Gjv6"
      },
      "source": [
        "history = ae.fit(x=train_data, y=train_data,\n",
        "                shuffle=True,\n",
        "                epochs=20,\n",
        "                batch_size=16,\n",
        "                validation_data=(test_data, test_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N57tO61TVA-K"
      },
      "source": [
        "e.save(\"/content/drive/MyDrive/Suga/encoder.h5\")\n",
        "d.save(\"/content/drive/MyDrive/Suga/decoder.h5\")\n",
        "ae.save(\"/content/drive/MyDrive/Suga/autoencoder.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7lZe8XIuua7"
      },
      "source": [
        "encoder = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/Suga/encoder.h5\", compile=False)\n",
        "decoder = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/Suga/decoder.h5\", compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bet4XE9A1iA0"
      },
      "source": [
        "def generate_z(encoder, spec):\n",
        "    \"\"\"\n",
        "    Determine the latent representation of a spectrogram.\n",
        "    Args:\n",
        "        encoder (obj): trained Keras encoder network.\n",
        "        spec (ndarray): spectrogram of shape (freqs, time).\n",
        "    Returns:\n",
        "        z (ndarray): latent vector of shape (1, 1, 1, 3)\n",
        "    \"\"\"\n",
        "    # fix shape (may be longer or shorter)\n",
        "    spec_shape = (encoder.input_shape[1], encoder.input_shape[2])\n",
        "    spec = fix_specgram_shape(spec, spec_shape)\n",
        "\n",
        "    # reshape for input to the encoder\n",
        "    spec = np.reshape(spec, (1, spec.shape[0], spec.shape[1], 1))\n",
        "\n",
        "    # predict embedding to latent vector z\n",
        "    z = encoder.predict(spec)\n",
        "\n",
        "    return z\n",
        "\n",
        "def generate_specgram(decoder, z):\n",
        "    \"\"\"\n",
        "    Generate a spectrogram from a latent representation.\n",
        "    Args:\n",
        "        decoder (obj): trained Keras decoder network.\n",
        "        z (ndarray): latent vector of shape (1, 1, 1, 3).\n",
        "    Returns:\n",
        "        spec (ndarray): spectrogram of shape (freqs, time).\n",
        "    \"\"\"\n",
        "    spec = decoder.predict(z) # predict spectrogram\n",
        "    spec = np.reshape(spec, (spec.shape[1], spec.shape[2]))\n",
        "    return spec\n",
        "\n",
        "def audio_from_specgram(spec, rate, output):\n",
        "    \"\"\"\n",
        "    Reconstruct audio and save it to file.\n",
        "    Args:\n",
        "        spec (ndarray): spectrogram of shape (freqs, time).\n",
        "        rate (int): sample rate of input audio.\n",
        "        output (str): path to output file.\n",
        "    \"\"\"\n",
        "    spec = np.reshape(spec, (spec.shape[0], spec.shape[1], 1)) # reshape\n",
        "    audio = ispecgram(spec, n_fft=1024, hop_length=256, mag_only=True, num_iters=1000)\n",
        "    sf.write(output + '.wav', audio, rate) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5wSEWmr3qmV"
      },
      "source": [
        "# def get_model():\n",
        "#   return VAE(name=\"vae\")\n",
        "\n",
        "\n",
        "# model = vae\n",
        "# # Save the model\n",
        "# model.save('/content/drive/MyDrive/Suga',save_format='tf')\n",
        "\n",
        "# # Recreate the exact same model purely from the file\n",
        "# # new_model = keras.models.load_model('/content/drive/MyDrive/Suga')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeXb8Z8NHrJa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "cdf880bc-7732-41a6-e276-7b4ac8151ec1"
      },
      "source": [
        "audio_from_specgram(test1,16000,output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e4ea10c65792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maudio_from_specgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLbPwSXOvOLA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "530d8841-8da7-41c8-ce3f-d739b5776a45"
      },
      "source": [
        "idx = 0\n",
        "for b in np.linspace(-2, 2, num=10):\n",
        "    for c in np.linspace(-2, 2, num=10):\n",
        "        print(\"{:04d} | z = [ {:+0.3f} {:+0.3f}]\".format(idx,b, c))\n",
        "        z = np.reshape(np.array([b, c]), (1, 1, 1, 2)) # think i want to fix this in my model\n",
        "        filename = \"_\".join([\"({:+0.3f})\".format(dim) for dim in np.reshape(z, (2))])\n",
        "        filename = \"{:04d}_{}\".format(idx, filename)\n",
        "        filepath = os.path.join('pre_compute_demo2', filename)\n",
        "        spec = generate_specgram(decoder, z)\n",
        "        audio_from_specgram(spec, 16000, filepath)\n",
        "        idx += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000 | z = [ -2.000 -2.000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b04338c2f87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pre_compute_demo2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_specgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0maudio_from_specgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1d9cd32cac57>\u001b[0m in \u001b[0;36maudio_from_specgram\u001b[0;34m(spec, rate, output)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mispecgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(file, data, samplerate, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     with SoundFile(file, 'w', samplerate, channels,\n\u001b[0;32m--> 315\u001b[0;31m                    subtype, endian, format, closefd) as f:\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    627\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid file: {0!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0;31m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error opening 'pre_compute_demo2/0000_(-2.000)_(-2.000).wav': System error."
          ]
        }
      ]
    }
  ]
}